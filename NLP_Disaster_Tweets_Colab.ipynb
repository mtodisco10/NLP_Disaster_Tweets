{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Disaster_Tweets_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMI7SkdjBLydnLoFWQlByhz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtodisco10/NLP_Disaster_Tweets/blob/master/NLP_Disaster_Tweets_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7F3zawnfO8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtaVnThZik01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "sample = pd.read_csv('sample_submission.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMMT0BhTis0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "d60ad2a8-fe02-450e-f63c-8478d0d75c72"
      },
      "source": [
        "pd.DataFrame({'count': train.target.value_counts(), \n",
        "              'percentage': train.target.value_counts(normalize=True)})"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4342</td>\n",
              "      <td>0.57034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3271</td>\n",
              "      <td>0.42966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   count  percentage\n",
              "0   4342     0.57034\n",
              "1   3271     0.42966"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUuLGKoDiwYG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "70b8f262-794c-4df9-9c6b-6db4fec75caf"
      },
      "source": [
        "train[\"target\"].value_counts().plot(kind='bar')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb4c9f99e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXzu4F52izHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_keywords(series):\n",
        "    mapper = {}\n",
        "    u_series = series.unique()\n",
        "    for i in range(len(u_series)):\n",
        "        mapper[u_series[i]] = i\n",
        "        \n",
        "    return mapper\n",
        "\n",
        "train_keyword_map = map_keywords(train.keyword)\n",
        "\n",
        "train['keyword_num'] = train['keyword'].map(train_keyword_map)\n",
        "test['keyword_num'] = test['keyword'].map(train_keyword_map)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsRlyNqvjXdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9b160321-3d18-472a-f5f2-6d9bebc77fda"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MZ_uXzbi1vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_preprocessing(data):\n",
        "    #remove whitespace and lower all words\n",
        "    data = data.apply(lambda x: x.strip().lower())\n",
        "    #replace digits\n",
        "    data = data.apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "    #replace punctuation\n",
        "    data = data.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
        "    #tokenize\n",
        "    data = data.apply(lambda x : word_tokenize(x))\n",
        "    #filter out stopwords\n",
        "    data = data.apply(lambda x: [word for word in x if word not in stop_words])\n",
        "    #remove inflection and return base word\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    data = data.apply(lambda x: [lemmatizer.lemmatize(word, pos ='v') for word in x])\n",
        "    #parts of speech tagging\n",
        "    #data = data.apply(lambda x: [pos_tag(x)])\n",
        "    return data\n",
        "\n",
        "train['pro_text'] = text_preprocessing(train.text)\n",
        "test['pro_text'] = text_preprocessing(test.text)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "317Azhs4jglW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ef479aea-9350-4e0f-a16d-3007597a8779"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "#joining words and fit transofrming\n",
        "vector = vectorizer.fit_transform([\"\".join(i) for i in train[\"pro_text\"]])\n",
        "vector = vector.todense()\n",
        "vector = np.concatenate((vector, np.reshape(np.array(train[\"keyword_num\"]), (train.keyword.shape[0],-1))), axis=1)\n",
        "print(vector.shape)\n",
        "\n",
        "# vector_test = vectorizer.fit_transform([\"\".join(i) for i in test[\"text\"]])\n",
        "vector_test = vectorizer.transform([\"\".join(i) for i in test[\"pro_text\"]])\n",
        "vector_test = vector_test.todense()\n",
        "vector_test = np.concatenate((vector_test, np.reshape(np.array(test[\"keyword_num\"]), (test.keyword.shape[0],-1))), axis=1)\n",
        "print(vector_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7613, 8037)\n",
            "(3263, 8037)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWbKOFtUjkBo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(vector, train['target'], train_size = 0.75)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV_skRw-faho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a4daeec2-5354-4b83-ec27-9d8e358229e5"
      },
      "source": [
        "%%time\n",
        "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-24_H-1024_A-16/1\"\n",
        "bert_layer = hub.KerasLayer(module_url, trainable=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.1 s, sys: 2.12 s, total: 14.2 s\n",
            "Wall time: 13.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE-Xu22Lfibt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "            \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len - len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
        "        tokens += [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "    \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7m88v78mF90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bert import tokenization"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mq4sH95fubs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.gfile = tf.io.gfile\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hh5pUiekzcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input = bert_encode([\" \".join(i) for i in train.pro_text], tokenizer, max_len=160)\n",
        "test_input = bert_encode([\" \".join(i) for i in test.pro_text], tokenizer, max_len=160)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwmG0D0Mk3Yc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(bert_layer, max_len=512):\n",
        "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    out = Dense(1, activation='sigmoid')(clf_output)\n",
        "    \n",
        "    model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(Adam(lr=2e-6), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX81FnRsl0fk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7074df0c-9d9a-4971-85c5-5c917a370a41"
      },
      "source": [
        "model = build_model(bert_layer, max_len=160)\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 160)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 1024), (None 335141889   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 1024)]       0           keras_layer[0][1]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            1025        tf_op_layer_strided_slice[0][0]  \n",
            "==================================================================================================\n",
            "Total params: 335,142,914\n",
            "Trainable params: 335,142,913\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbbw2LWmnEAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73356f0f-61c6-4f6f-c1fe-c2fa4b4db792"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "early = EarlyStopping(monitor='val_loss',mode='auto', baseline=None, restore_best_weights=False)\n",
        "train_history = model.fit(\n",
        "    train_input, train.target,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    callbacks=[early], verbose=1\n",
        ")\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "147/381 [==========>...................] - ETA: 5:54 - loss: 0.5377 - accuracy: 0.7449"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VVL4YtInH1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}